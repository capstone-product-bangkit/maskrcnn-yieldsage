{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1925688,"sourceType":"datasetVersion","datasetId":1148542},{"sourceId":8691314,"sourceType":"datasetVersion","datasetId":5211669}],"dockerImageVersionId":30056,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Brain Tumor Detection using Mask R-CNN ","metadata":{}},{"cell_type":"markdown","source":"# 1-Import Libraries","metadata":{}},{"cell_type":"code","source":"pip install -U scikit-image==0.16.2","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-06-17T18:35:23.233078Z","iopub.execute_input":"2024-06-17T18:35:23.233496Z","iopub.status.idle":"2024-06-17T18:35:38.812269Z","shell.execute_reply.started":"2024-06-17T18:35:23.233395Z","shell.execute_reply":"2024-06-17T18:35:38.811115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os \nimport sys\nfrom tqdm import tqdm\nimport cv2\nimport numpy as np\nimport json\nimport skimage.draw\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport random\nfrom pathlib import Path\nfrom IPython.display import clear_output\n\nDATASET_DIR = '/kaggle/input/palm-oil-json/palm-oil'\nROOT_DIR = Path('/kaggle/working')\n#-------- directory to save logs and trained model----\nMODEL_DIR = os.path.join(ROOT_DIR, 'logs')\nDEFAULT_LOGS_DIR = 'logs' ","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:35:38.814899Z","iopub.execute_input":"2024-06-17T18:35:38.815335Z","iopub.status.idle":"2024-06-17T18:35:39.562566Z","shell.execute_reply.started":"2024-06-17T18:35:38.815291Z","shell.execute_reply":"2024-06-17T18:35:39.561761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2-Installing","metadata":{}},{"cell_type":"markdown","source":"## 2.1-Install the previous version of TensorFlow(1.14)","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow==1.14\nimport tensorflow as tf\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:35:39.564250Z","iopub.execute_input":"2024-06-17T18:35:39.564687Z","iopub.status.idle":"2024-06-17T18:36:35.184261Z","shell.execute_reply.started":"2024-06-17T18:35:39.564645Z","shell.execute_reply":"2024-06-17T18:36:35.183377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:36:35.186106Z","iopub.execute_input":"2024-06-17T18:36:35.186526Z","iopub.status.idle":"2024-06-17T18:36:35.195173Z","shell.execute_reply.started":"2024-06-17T18:36:35.186486Z","shell.execute_reply":"2024-06-17T18:36:35.194205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Install Keras version (2.1.5)","metadata":{}},{"cell_type":"code","source":"!pip install keras==2.1.5\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:36:35.199028Z","iopub.execute_input":"2024-06-17T18:36:35.199449Z","iopub.status.idle":"2024-06-17T18:36:45.417197Z","shell.execute_reply.started":"2024-06-17T18:36:35.199391Z","shell.execute_reply":"2024-06-17T18:36:45.416227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.3 Install pycocotools","metadata":{}},{"cell_type":"code","source":"!pip install pycocotools\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:36:45.420302Z","iopub.execute_input":"2024-06-17T18:36:45.420623Z","iopub.status.idle":"2024-06-17T18:36:53.046241Z","shell.execute_reply.started":"2024-06-17T18:36:45.420593Z","shell.execute_reply":"2024-06-17T18:36:53.045131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3-Download the Model Mask_RCNN ","metadata":{}},{"cell_type":"code","source":"!git clone https://www.github.com/matterport/Mask_RCNN.git\n!rm -rf .git # to prevent an error when the kernel is committed\n!rm -rf images assets # to prevent displaying images at the bottom of a kernel\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:36:53.047956Z","iopub.execute_input":"2024-06-17T18:36:53.048302Z","iopub.status.idle":"2024-06-17T18:37:02.377324Z","shell.execute_reply.started":"2024-06-17T18:36:53.048247Z","shell.execute_reply":"2024-06-17T18:37:02.376286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Root directory of the project\nROOT_DIR = os.path.abspath('Mask_RCNN/')\n# Import Mask RCNN\nsys.path.append(ROOT_DIR) \nfrom mrcnn.config import Config\nfrom mrcnn import utils\nfrom mrcnn.model import log\nimport mrcnn.model as modellib\nfrom mrcnn import visualize\n\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:37:02.378882Z","iopub.execute_input":"2024-06-17T18:37:02.379185Z","iopub.status.idle":"2024-06-17T18:37:03.387778Z","shell.execute_reply.started":"2024-06-17T18:37:02.379156Z","shell.execute_reply":"2024-06-17T18:37:03.386911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4-Import COCO config","metadata":{}},{"cell_type":"code","source":"sys.path.append(os.path.join(ROOT_DIR, 'samples/coco/'))\nimport coco\n\n# Local path to trained weights file\nCOCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n# Download COCO trained weights from Releases if needed\nif not os.path.exists(COCO_MODEL_PATH):\n    utils.download_trained_weights(COCO_MODEL_PATH)\nplt.rcParams['figure.facecolor'] = 'white'\n\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:37:03.388917Z","iopub.execute_input":"2024-06-17T18:37:03.389191Z","iopub.status.idle":"2024-06-17T18:37:05.280473Z","shell.execute_reply.started":"2024-06-17T18:37:03.389165Z","shell.execute_reply":"2024-06-17T18:37:05.279370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TumorConfig(Config):\n    NAME = 'Brain_Tumor_Detector'\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n    NUM_CLASSES = 1 + 1 \n    DETECTION_MIN_CONFIDENCE = 0.9    \n    STEPS_PER_EPOCH = 80\n    LEARNING_RATE = 0.005    \nconfig = TumorConfig()\nconfig.display()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:37:05.282199Z","iopub.execute_input":"2024-06-17T18:37:05.282646Z","iopub.status.idle":"2024-06-17T18:37:05.293496Z","shell.execute_reply.started":"2024-06-17T18:37:05.282603Z","shell.execute_reply":"2024-06-17T18:37:05.291707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5-Brain Tumor Dataset","metadata":{}},{"cell_type":"code","source":"class BrainTumorDataset(utils.Dataset):\n    def load_brain_scan(self, dataset_dir, subset):\n        \"\"\"Load a subset of the FarmCow dataset.\n        dataset_dir: Root directory of the dataset.\n        subset: Subset to load: train or val\n        \"\"\"\n        # Add classes. We have only one class to add.\n        self.add_class(\"tumor\", 1, \"tumor\")\n\n        # Train or validation dataset?\n        assert subset in [\"train\", \"valid\", 'test']\n        dataset_dir = os.path.join(dataset_dir, subset)\n\n        annotations = json.load(open(os.path.join(dataset_dir,'annotation_json'+'.json')))\n        annotations = list(annotations.values())  # don't need the dict keys\n\n        # The VIA tool saves images in the JSON even if they don't have any\n        # annotations. Skip unannotated images.\n        annotations = [a for a in annotations if a['regions']]\n\n        # Add images\n        for a in annotations:\n            # Get the x, y coordinaets of points of the polygons that make up\n            # the outline of each object instance. These are stores in the\n            # shape_attributes (see json format above)\n            # The if condition is needed to support VIA versions 1.x and 2.x.\n            if type(a['regions']) is dict:\n                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n            else:\n                polygons = [r['shape_attributes'] for r in a['regions']]\n\n            # load_mask() needs the image size to convert polygons to masks.\n            # Unfortunately, VIA doesn't include it in JSON, so we must read\n            # the image. This is only managable since the dataset is tiny.\n            image_path = os.path.join(dataset_dir, a['filename'])\n            \n            image = skimage.io.imread(image_path)\n            height, width = image.shape[:2]\n\n            self.add_image(\n                \"tumor\",\n                image_id=a['filename'],  # use file name as a unique image id\n                path=image_path,\n                width=width, \n                height=height,\n                polygons=polygons\n            )\n\n    def load_mask(self, image_id):\n        \"\"\"Generate instance masks for an image.\n       Returns:\n        masks: A bool array of shape [height, width, instance count] with\n            one mask per instance.\n        class_ids: a 1D array of class IDs of the instance masks.\n        \"\"\"\n        # If not a farm_cow dataset image, delegate to parent class.\n        image_info = self.image_info[image_id]\n        if image_info[\"source\"] != \"tumor\":\n            return super(self.__class__, self).load_mask(image_id)\n\n        # Convert polygons to a bitmap mask of shape\n        # [height, width, instance_count]\n        info = self.image_info[image_id]\n        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n                        dtype=np.uint8)\n        for i, p in enumerate(info[\"polygons\"]):\n            # Get indexes of pixels inside the polygon and set them to 1\n            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n            mask[rr, cc, i] = 1\n\n        # Return mask, and array of class IDs of each instance. Since we have\n        # one class ID only, we return an array of 1s\n        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n\n    def image_reference(self, image_id):\n        \"\"\"Return the path of the image.\"\"\"\n        info = self.image_info[image_id]\n        if info[\"source\"] == \"tumor\":\n            return info[\"path\"]\n        else:\n            super(self.__class__, self).image_reference(image_id)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:37:05.295646Z","iopub.execute_input":"2024-06-17T18:37:05.296113Z","iopub.status.idle":"2024-06-17T18:37:05.318276Z","shell.execute_reply.started":"2024-06-17T18:37:05.296068Z","shell.execute_reply":"2024-06-17T18:37:05.317308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training dataset.\ndataset_train = BrainTumorDataset()\ndataset_train.load_brain_scan(DATASET_DIR, 'train')\ndataset_train.prepare()\n\n# Validation dataset\ndataset_val = BrainTumorDataset()\ndataset_val.load_brain_scan(DATASET_DIR, 'valid')\ndataset_val.prepare()\n\ndataset_test = BrainTumorDataset()\ndataset_test.load_brain_scan(DATASET_DIR, 'test')\ndataset_test.prepare()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:37:05.319980Z","iopub.execute_input":"2024-06-17T18:37:05.320480Z","iopub.status.idle":"2024-06-17T18:37:44.203567Z","shell.execute_reply.started":"2024-06-17T18:37:05.320432Z","shell.execute_reply":"2024-06-17T18:37:44.202433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6-Visualizing Some Samples","metadata":{}},{"cell_type":"code","source":"print(dataset_train.image_reference(6))\nimage = dataset_train.load_image(6)\nmask, class_ids = dataset_train.load_mask(6)\nvisualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=1)\n    ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-17T18:37:44.205144Z","iopub.execute_input":"2024-06-17T18:37:44.205570Z","iopub.status.idle":"2024-06-17T18:37:44.998919Z","shell.execute_reply.started":"2024-06-17T18:37:44.205525Z","shell.execute_reply":"2024-06-17T18:37:44.997940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dataset_train.image_reference(30))\nimage = dataset_train.load_image(30)\nmask, class_ids = dataset_train.load_mask(30)\nvisualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=1)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-17T18:37:45.000116Z","iopub.execute_input":"2024-06-17T18:37:45.000429Z","iopub.status.idle":"2024-06-17T18:37:45.671961Z","shell.execute_reply.started":"2024-06-17T18:37:45.000390Z","shell.execute_reply":"2024-06-17T18:37:45.671107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dataset_train.image_reference(40))\nimage = dataset_train.load_image(40)\nmask, class_ids = dataset_train.load_mask(40)\nvisualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=1)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-17T18:37:45.673353Z","iopub.execute_input":"2024-06-17T18:37:45.673743Z","iopub.status.idle":"2024-06-17T18:37:46.406564Z","shell.execute_reply.started":"2024-06-17T18:37:45.673708Z","shell.execute_reply":"2024-06-17T18:37:46.405368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7-Build the Mask R-CNN Model Architecture\n","metadata":{}},{"cell_type":"code","source":"#-------------- Create model object in training mode------------------------\nmodel = modellib.MaskRCNN(\n    mode='training', \n    config=config, \n    model_dir=DEFAULT_LOGS_DIR\n)\n#-------------- Load weights trained on MS-COCO ---------------------------\nmodel.load_weights(\n    COCO_MODEL_PATH, \n    by_name=True, \n    exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"]\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:37:46.408178Z","iopub.execute_input":"2024-06-17T18:37:46.408608Z","iopub.status.idle":"2024-06-17T18:37:58.651396Z","shell.execute_reply.started":"2024-06-17T18:37:46.408568Z","shell.execute_reply":"2024-06-17T18:37:58.650618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8-Training","metadata":{}},{"cell_type":"code","source":"model.train(\n    dataset_train, dataset_val,\n    learning_rate=config.LEARNING_RATE,\n    epochs=10,\n    layers='heads'\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:37:58.652852Z","iopub.execute_input":"2024-06-17T18:37:58.653142Z","iopub.status.idle":"2024-06-18T00:58:53.718579Z","shell.execute_reply.started":"2024-06-17T18:37:58.653114Z","shell.execute_reply":"2024-06-18T00:58:53.717514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9-Helper Functions\n","metadata":{}},{"cell_type":"code","source":"def display_image(dataset, ind):\n    plt.figure(figsize=(5,5))\n    plt.imshow(dataset.load_image(ind))\n    plt.xticks([])\n    plt.yticks([])\n    plt.title('Original Image')\n    plt.show()\ndef get_ax(rows=1, cols=1, size=5):\n    \"\"\"Return a Matplotlib Axes array to be used in\n    all visualizations in the notebook. Provide a\n    central point to control graph sizes.\n    \n    Change the default size attribute to control the size\n    of rendered images\n    \"\"\"\n    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n    return ax\n\ndef predict_and_plot_differences(dataset, img_id):\n    original_image, image_meta, gt_class_id, gt_box, gt_mask =\\\n        modellib.load_image_gt(dataset, config, \n                               img_id, use_mini_mask=False)\n\n    results = model.detect([original_image], verbose=0)\n    r = results[0]\n\n    visualize.display_differences(\n        original_image,\n        gt_box, gt_class_id, gt_mask,\n        r['rois'], r['class_ids'], r['scores'], r['masks'],\n        class_names = ['tumor'], title=\"\", ax=get_ax(),\n        show_mask=True, show_box=True)\n\ndef calculate_areas(masks):\n    \"\"\"Calculate the area of each mask.\"\"\"\n    areas = []\n    for i in range(masks.shape[-1]):\n        mask = masks[:, :, i]\n        area = np.sum(mask)\n        areas.append(area)\n    return areas\n\ndef predict(dataset, img_id):\n    # Load the image and run detection\n    original_image, image_meta, gt_class_id, gt_box, gt_mask =\\\n        modellib.load_image_gt(dataset, config, \n                               img_id, use_mini_mask=False)\n\n    results = model.detect([original_image], verbose=0)\n    r = results[0]\n\n    # Calculate areas of detected items\n    areas = calculate_areas(r['masks'])\n\n    # Display predictions\n    visualize.display_instances(\n        original_image,\n        r['rois'], r['masks'], r['class_ids'], \n        dataset.class_names, r['scores'],\n        title=\"Predicted Results\", ax=get_ax(),\n        show_mask=True, show_bbox=True)\n\n    # Print the area of each detected item\n    for i, area in enumerate(areas):\n        print(f\"Item {i + 1}: Area = {area} pixels\")\n\n# Assuming modellib and visualize are already imported and configured","metadata":{"execution":{"iopub.status.busy":"2024-06-18T00:58:53.720970Z","iopub.execute_input":"2024-06-18T00:58:53.721480Z","iopub.status.idle":"2024-06-18T00:58:53.744057Z","shell.execute_reply.started":"2024-06-18T00:58:53.721400Z","shell.execute_reply":"2024-06-18T00:58:53.743093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 10-Inference","metadata":{}},{"cell_type":"code","source":"# Recreate the model in inference mode\nmodel = modellib.MaskRCNN(\n    mode=\"inference\", \n    config=config,\n    model_dir=DEFAULT_LOGS_DIR\n)\n\n\nmodel_path = model.find_last()\n#model_path=\"../input/mask-r-cnn-tumor-brain/logs/tumor_detector20210209T1932/mask_rcnn_tumor_detector_0002.h5\"\n# Load trained weights\nprint(\"Loading weights from \", model_path)\nmodel.load_weights(model_path, by_name=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T00:58:53.745934Z","iopub.execute_input":"2024-06-18T00:58:53.746352Z","iopub.status.idle":"2024-06-18T00:59:05.856926Z","shell.execute_reply.started":"2024-06-18T00:58:53.746312Z","shell.execute_reply":"2024-06-18T00:59:05.855766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 11-Detect Tumors and Visualize the Results","metadata":{}},{"cell_type":"code","source":"print(\"Sample 1\")\nind = 10\ndisplay_image(dataset_val, ind)\npredict(dataset_val, ind)\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-18T00:59:05.858179Z","iopub.execute_input":"2024-06-18T00:59:05.858526Z","iopub.status.idle":"2024-06-18T00:59:21.467126Z","shell.execute_reply.started":"2024-06-18T00:59:05.858493Z","shell.execute_reply":"2024-06-18T00:59:21.466113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Sample 2\")\nind = 16\ndisplay_image(dataset_val, ind)\npredict_and_plot_differences(dataset_val, ind)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-18T00:59:21.469062Z","iopub.execute_input":"2024-06-18T00:59:21.469506Z","iopub.status.idle":"2024-06-18T00:59:46.448832Z","shell.execute_reply.started":"2024-06-18T00:59:21.469460Z","shell.execute_reply":"2024-06-18T00:59:46.447891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Sample 3\")\nind = 0\ndisplay_image(dataset_test, ind)\npredict_and_plot_differences(dataset_test, ind)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-18T00:59:46.450204Z","iopub.execute_input":"2024-06-18T00:59:46.450607Z","iopub.status.idle":"2024-06-18T01:00:11.029468Z","shell.execute_reply.started":"2024-06-18T00:59:46.450570Z","shell.execute_reply":"2024-06-18T01:00:11.028381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Sample 4\")\nind = 2\ndisplay_image(dataset_test, ind)\npredict_and_plot_differences(dataset_test, ind)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-18T01:00:11.031072Z","iopub.execute_input":"2024-06-18T01:00:11.031530Z","iopub.status.idle":"2024-06-18T01:00:39.136524Z","shell.execute_reply.started":"2024-06-18T01:00:11.031488Z","shell.execute_reply":"2024-06-18T01:00:39.135689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Sample 5\")\nind = 3\ndisplay_image(dataset_test, ind)\npredict_and_plot_differences(dataset_test, ind)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-18T01:00:39.137725Z","iopub.execute_input":"2024-06-18T01:00:39.137999Z","iopub.status.idle":"2024-06-18T01:01:06.729643Z","shell.execute_reply.started":"2024-06-18T01:00:39.137972Z","shell.execute_reply":"2024-06-18T01:01:06.728547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 12- References\n1. https://www.kaggle.com/ruslankl/brain-tumor-detection-v2-0-mask-r-cnn\n","metadata":{}}]}